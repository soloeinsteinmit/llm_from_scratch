# **Data Preprocessing**

**4 steps:**

1. Tokenization which inlcudes

   - word based
   - subword based(BPE tokenizer)
   - character based

2. Token embeddings: converting token IDs to vectors

3. positional embeddings: encoding information about the position of words in the a sentence or text

4. Input embeddings = Token ebeddings + postional embeddings

![](images/L12_preprocess.png)
